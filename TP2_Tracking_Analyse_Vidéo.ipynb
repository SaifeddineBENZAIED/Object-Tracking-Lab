{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ee7ab15",
   "metadata": {},
   "source": [
    "**TP2 (Tracking) -Analyse vidéo**\n",
    "\n",
    "Benzaied Saifeddine -RT5 groupe 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9851a2",
   "metadata": {},
   "source": [
    "<b>Object localization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58f76ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vidéo chargée avec succès\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Chargement de la vidéo\n",
    "video = cv2.VideoCapture(\"my_video_TPsAV.mp4\")\n",
    "\n",
    "# Vérification si la vidéo a bien été chargée\n",
    "if not video.isOpened():\n",
    "    print(\"Erreur lors de l'ouverture de la vidéo\")\n",
    "    exit()\n",
    "\n",
    "print(\"Vidéo chargée avec succès\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d2cd78",
   "metadata": {},
   "source": [
    "<i>Segmentation avec la méthode Adaptive Background Subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8416ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fin de la vidéo ou erreur de lecture.\n"
     ]
    }
   ],
   "source": [
    "# Coefficient d'adaptation pour la mise à jour du fond\n",
    "alpha = 0.6\n",
    "\n",
    "# Lire la première frame pour initialiser l'image de fond\n",
    "ret, frame = video.read()\n",
    "if not ret:\n",
    "    print(\"Erreur : impossible de lire la première frame.\")\n",
    "    exit()\n",
    "\n",
    "background = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        print(\"Fin de la vidéo ou erreur de lecture.\")\n",
    "        break\n",
    "\n",
    "    # Convertir la frame actuelle en niveaux de gris\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Calculer la différence absolue\n",
    "    diff = cv2.absdiff(background.astype(np.uint8), gray)\n",
    "\n",
    "    # Seuillage pour obtenir le masque binaire\n",
    "    _, mask = cv2.threshold(diff, 30, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Nettoyage du masque : combinaison d'ouverture et de fermeture\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "\n",
    "    # Fermeture pour combler les petits trous\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Ouverture pour éliminer le bruit\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # Afficher le masque segmenté\n",
    "    cv2.imshow(\"Masque segmenté (Adaptive Background)\", mask)\n",
    "\n",
    "    # Mise à jour du fond avec la méthode Adaptive Background Subtraction\n",
    "    background = alpha * gray + (1 - alpha) * background\n",
    "\n",
    "    # Quitter si 'q' est pressé\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9f97db",
   "metadata": {},
   "source": [
    "<i>Localisation d'objet avec la méthode Adaptive Background Subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85e1802c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fin de la vidéo ou erreur de lecture.\n"
     ]
    }
   ],
   "source": [
    "# Charger la vidéo\n",
    "video = cv2.VideoCapture('my_video_TPsAV.mp4')\n",
    "if not video.isOpened():\n",
    "    print(\"Erreur : impossible de charger la vidéo.\")\n",
    "    exit()\n",
    "\n",
    "# Coefficient d'adaptation pour la mise à jour du fond\n",
    "alpha = 0.6\n",
    "\n",
    "# Lire la première frame pour initialiser l'image de fond\n",
    "ret, frame = video.read()\n",
    "if not ret:\n",
    "    print(\"Erreur : impossible de lire la première frame.\")\n",
    "    exit()\n",
    "\n",
    "background = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        print(\"Fin de la vidéo ou erreur de lecture.\")\n",
    "        break\n",
    "\n",
    "    # Convertir la frame actuelle en niveaux de gris\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Calculer la différence absolue\n",
    "    diff = cv2.absdiff(background.astype(np.uint8), gray)\n",
    "\n",
    "    # Seuillage pour obtenir le masque binaire\n",
    "    _, mask = cv2.threshold(diff, 30, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Nettoyage du masque : combinaison d'ouverture et de fermeture\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "\n",
    "    # Fermeture pour combler les petits trous\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Ouverture pour éliminer le bruit\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # Trouver les contours\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Parcourir les contours et dessiner les boîtes englobantes\n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) > 3500:  # Filtrer les petits objets\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Afficher la frame avec les boîtes englobantes\n",
    "    cv2.imshow(\"Frame avec boîtes englobantes\", frame)\n",
    "\n",
    "    # Mise à jour du fond avec la méthode Adaptive Background Subtraction\n",
    "    background = alpha * gray + (1 - alpha) * background\n",
    "\n",
    "    # Quitter si 'q' est pressé\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec4c2f3",
   "metadata": {},
   "source": [
    "<i>Localisation d'objet avec la méthode basée sur les couleurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "889ec26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fin de la vidéo ou erreur de lecture.\n"
     ]
    }
   ],
   "source": [
    "# Charger la vidéo\n",
    "video = cv2.VideoCapture('my_video_TPsAV.mp4')\n",
    "if not video.isOpened():\n",
    "    print(\"Erreur : impossible de charger la vidéo.\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "\n",
    "# Définir les plages HSV pour détecter la couleur bleue\n",
    "lower_blue = np.array([100, 150, 50])  # Borne inférieure (teinte, saturation, luminosité)\n",
    "upper_blue = np.array([140, 255, 255])  # Borne supérieure\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        print(\"Fin de la vidéo ou erreur de lecture.\")\n",
    "        break\n",
    "\n",
    "    # Convertir l'image en espace HSV\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Créer un masque pour isoler les pixels bleus\n",
    "    mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "\n",
    "    # Nettoyage du masque avec des opérations morphologiques\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)  # Combler les trous\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)   # Supprimer le bruit\n",
    "\n",
    "    # Trouver les contours des régions bleues\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Initialiser une liste pour stocker les détections\n",
    "    detections = []\n",
    "\n",
    "    # Parcourir les contours et enregistrer les boîtes englobantes des objets pertinents\n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) > 7000:  # Filtrer les petits objets\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            detections.append([x, y, w, h])\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)  # Dessiner une boîte bleue\n",
    "\n",
    "    \n",
    "\n",
    "    # Afficher le masque et la frame avec suivi\n",
    "    cv2.imshow(\"Masque Bleu\", mask)\n",
    "    cv2.imshow(\"Frame avec suivi\", frame)\n",
    "\n",
    "    # Quitter si 'q' est pressé\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44adeef7",
   "metadata": {},
   "source": [
    "<b>Object Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e50f8a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tracker import *\n",
    "\n",
    "# Create tracker object\n",
    "tracker = EuclideanDistTracker()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6901f4",
   "metadata": {},
   "source": [
    "<i>Suivi d'objet avec la méthode Adaptive Background Subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc440770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{7: (151, 494)}\n",
      "{8: (137, 690)}\n",
      "{8: (151, 675)}\n",
      "{9: (205, 622)}\n",
      "{9: (218, 608)}\n",
      "{10: (92, 620)}\n",
      "{10: (108, 612)}\n",
      "{10: (131, 605)}\n",
      "{10: (150, 612)}\n",
      "{10: (167, 597)}\n",
      "{15: (240, 555), 16: (250, 429), 17: (566, 344), 18: (414, 580)}\n",
      "{15: (240, 555), 16: (269, 441), 17: (566, 344), 18: (414, 580)}\n",
      "{18: (414, 580), 15: (240, 555), 16: (293, 435), 19: (571, 383), 20: (434, 563), 21: (266, 554), 22: (468, 490)}\n",
      "{18: (414, 580), 15: (240, 555), 16: (293, 435), 19: (583, 378), 20: (434, 563), 21: (266, 554), 22: (468, 490)}\n",
      "{20: (454, 558), 21: (266, 554), 22: (468, 490), 16: (293, 435), 19: (583, 378), 23: (602, 93)}\n",
      "{20: (454, 558), 21: (287, 555), 22: (468, 490), 16: (293, 435), 19: (583, 378), 23: (602, 93)}\n",
      "{20: (454, 558), 21: (287, 555), 22: (489, 496), 16: (293, 435), 19: (583, 378), 23: (602, 93)}\n",
      "{20: (474, 565), 21: (287, 555), 22: (489, 496), 24: (326, 400)}\n",
      "{20: (474, 565), 21: (308, 551), 22: (489, 496), 24: (326, 400)}\n",
      "{28: (362, 491)}\n",
      "{28: (362, 491), 29: (734, 291), 30: (391, 497), 31: (430, 332)}\n",
      "{30: (399, 479), 31: (430, 332), 29: (734, 291), 32: (645, 154)}\n",
      "{30: (399, 479), 31: (430, 332), 29: (752, 284), 32: (645, 154), 33: (460, 325)}\n",
      "{30: (399, 479), 33: (478, 323), 29: (752, 284), 34: (720, 144), 35: (656, 60), 36: (420, 496)}\n",
      "{36: (439, 494), 33: (478, 323), 37: (775, 257), 38: (696, 155)}\n",
      "{36: (439, 494), 39: (764, 319), 40: (800, 44), 41: (458, 462)}\n",
      "{36: (439, 494), 39: (764, 319), 40: (820, 43), 41: (458, 462)}\n",
      "{41: (458, 462), 39: (782, 318), 40: (820, 43)}\n",
      "{39: (782, 318), 42: (573, 306), 43: (803, 67), 44: (825, 317)}\n",
      "{39: (782, 318), 42: (573, 306), 43: (809, 59), 44: (825, 317)}\n",
      "{44: (845, 313), 42: (573, 306), 43: (809, 59)}\n",
      "{44: (845, 313), 42: (597, 300), 43: (809, 59)}\n",
      "{44: (845, 313), 42: (597, 300), 43: (802, 75), 45: (847, 152)}\n",
      "{44: (868, 305), 42: (597, 300), 45: (847, 152), 43: (802, 75), 46: (534, 446)}\n",
      "{44: (868, 305), 42: (621, 298), 45: (847, 152), 43: (802, 75), 46: (534, 446)}\n",
      "{44: (868, 305), 42: (621, 298), 45: (867, 156), 43: (802, 75), 46: (534, 446)}\n",
      "{44: (868, 305), 42: (621, 298), 45: (867, 156), 43: (824, 77), 46: (534, 446)}\n",
      "{46: (534, 446), 44: (868, 305), 42: (636, 302), 45: (867, 156), 43: (824, 77)}\n",
      "{46: (534, 446), 44: (868, 305), 42: (636, 302), 45: (874, 134), 43: (824, 77)}\n",
      "{46: (534, 446), 44: (868, 305), 42: (636, 302), 45: (874, 134), 43: (805, 83)}\n",
      "{42: (636, 302), 45: (886, 135), 43: (805, 83), 47: (811, 391), 48: (660, 311)}\n",
      "{47: (811, 391), 48: (672, 323), 45: (886, 135), 49: (787, 484), 50: (570, 439), 51: (876, 363)}\n",
      "{49: (787, 491), 50: (570, 439), 51: (876, 363), 48: (672, 323), 52: (910, 145)}\n",
      "{49: (787, 491), 53: (915, 338), 54: (719, 321), 55: (944, 189), 56: (881, 92), 57: (915, 371)}\n",
      "{57: (915, 371), 54: (723, 335), 58: (931, 150), 59: (909, 412)}\n",
      "{59: (909, 412), 54: (744, 347), 60: (971, 212), 61: (945, 390)}\n",
      "{61: (945, 390), 54: (756, 341), 62: (998, 211), 63: (940, 425)}\n",
      "{63: (954, 428), 54: (756, 341), 64: (962, 208)}\n",
      "{63: (954, 428), 54: (768, 350), 64: (962, 208)}\n",
      "{63: (970, 432), 54: (768, 350)}\n",
      "{63: (970, 432), 65: (794, 394), 66: (1016, 245), 67: (679, 526), 68: (1004, 405)}\n",
      "{67: (679, 526), 68: (1004, 405), 65: (795, 383)}\n",
      "{67: (679, 526), 68: (1019, 409), 65: (795, 383)}\n",
      "{69: (803, 436)}\n",
      "{69: (820, 437), 70: (1028, 477)}\n",
      "{71: (750, 543), 72: (1063, 448), 73: (858, 412)}\n",
      "{71: (750, 543), 72: (1063, 448), 73: (856, 424), 74: (1032, 522)}\n",
      "{75: (841, 478), 76: (1094, 491)}\n",
      "{75: (858, 482), 76: (1094, 491)}\n",
      "{76: (1102, 513), 75: (858, 482), 77: (805, 556)}\n",
      "{77: (805, 556), 76: (1102, 513), 78: (933, 465), 79: (831, 570), 80: (1151, 478)}\n",
      "{79: (831, 570), 80: (1151, 478), 78: (949, 449), 81: (860, 569), 82: (1134, 517)}\n",
      "{83: (938, 516), 84: (1168, 518)}\n",
      "{84: (1190, 507), 83: (938, 516)}\n",
      "{84: (1190, 507), 83: (947, 526)}\n",
      "{84: (1190, 507), 83: (957, 536), 85: (1181, 553)}\n",
      "{85: (1186, 570), 83: (957, 536)}\n",
      "{85: (1186, 570), 83: (965, 547)}\n",
      "{85: (1192, 592), 83: (965, 547)}\n",
      "{85: (1192, 592), 83: (974, 564)}\n",
      "{85: (1192, 592), 83: (993, 575), 86: (1170, 620)}\n",
      "{86: (1170, 620), 83: (993, 594)}\n",
      "{93: (1033, 671)}\n",
      "Fin de la vidéo ou erreur de lecture.\n"
     ]
    }
   ],
   "source": [
    "# Coefficient d'adaptation pour la mise à jour du fond\n",
    "alpha = 0.6\n",
    "\n",
    "# Charger la vidéo\n",
    "video = cv2.VideoCapture('my_video_TPsAV.mp4')\n",
    "if not video.isOpened():\n",
    "    print(\"Erreur : impossible de charger la vidéo.\")\n",
    "    exit()\n",
    "\n",
    "# Lire la première frame pour initialiser l'image de fond\n",
    "ret, frame = video.read()\n",
    "if not ret:\n",
    "    print(\"Erreur : impossible de lire la première frame.\")\n",
    "    exit()\n",
    "\n",
    "background = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Initialiser le tracker\n",
    "tracker = EuclideanDistTracker()\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        print(\"Fin de la vidéo ou erreur de lecture.\")\n",
    "        break\n",
    "\n",
    "    # Convertir la frame actuelle en niveaux de gris\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Calculer la différence absolue\n",
    "    diff = cv2.absdiff(background.astype(np.uint8), gray)\n",
    "\n",
    "    # Seuillage pour obtenir le masque binaire\n",
    "    _, mask = cv2.threshold(diff, 30, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Nettoyage du masque : combinaison d'ouverture et de fermeture\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "\n",
    "    # Fermeture pour combler les petits trous\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Ouverture pour éliminer le bruit\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # Trouver les contours\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Initialiser une liste pour stocker les détections\n",
    "    detections = []\n",
    "\n",
    "    # Parcourir les contours et enregistrer les boîtes englobantes des objets pertinents\n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) > 3500:  # Filtrer les petits objets\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            detections.append([x, y, w, h])\n",
    "\n",
    "    # Mettre à jour le tracker avec les nouvelles détections\n",
    "    boxes_ids = tracker.update(detections)\n",
    "\n",
    "    # Visualiser les boîtes englobantes et les IDs\n",
    "    for box_id in boxes_ids:\n",
    "        x, y, w, h, id = box_id\n",
    "        cv2.putText(frame, f\"ID {id}\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Afficher la frame avec le suivi\n",
    "    cv2.imshow(\"Frame avec suivi\", frame)\n",
    "\n",
    "    # Mise à jour du fond avec la méthode Adaptive Background Subtraction\n",
    "    background = alpha * gray + (1 - alpha) * background\n",
    "\n",
    "    # Quitter si 'q' est pressé\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0133b2de",
   "metadata": {},
   "source": [
    "<i>Suivi d'objet avec la méthode basée sur les couleurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50b27fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: (127, 656)}\n",
      "{3: (136, 604)}\n",
      "{3: (140, 594)}\n",
      "{3: (142, 586)}\n",
      "{3: (143, 573)}\n",
      "{3: (146, 563)}\n",
      "{3: (149, 547)}\n",
      "{5: (169, 544)}\n",
      "{5: (178, 539)}\n",
      "{6: (195, 507)}\n",
      "{6: (202, 484)}\n",
      "{6: (208, 494)}\n",
      "{6: (215, 488)}\n",
      "{6: (220, 487)}\n",
      "{7: (234, 472)}\n",
      "{7: (242, 458)}\n",
      "{7: (256, 454)}\n",
      "{7: (267, 442)}\n",
      "{7: (282, 433)}\n",
      "{7: (300, 422)}\n",
      "{13: (446, 305)}\n",
      "{13: (465, 293)}\n",
      "{14: (506, 304)}\n",
      "{14: (526, 308)}\n",
      "{19: (675, 281)}\n",
      "{20: (703, 251)}\n",
      "{22: (735, 257)}\n",
      "{26: (846, 332)}\n",
      "{26: (858, 344)}\n",
      "{26: (871, 353)}\n",
      "{27: (792, 421), 28: (1009, 304)}\n",
      "{31: (906, 412)}\n",
      "{31: (909, 418)}\n",
      "{32: (899, 473), 33: (1055, 311)}\n",
      "{32: (899, 473), 33: (1055, 335)}\n",
      "{37: (1114, 384), 38: (985, 435)}\n",
      "{38: (1004, 443)}\n",
      "{38: (994, 446), 39: (1166, 392)}\n",
      "{39: (1172, 402), 38: (994, 446)}\n",
      "{43: (1204, 425), 44: (1021, 469)}\n",
      "{46: (1105, 517)}\n",
      "{46: (1111, 532)}\n",
      "{50: (1103, 573)}\n",
      "{50: (1106, 579)}\n",
      "{54: (1201, 627)}\n",
      "{54: (1213, 639)}\n",
      "Fin de la vidéo ou erreur de lecture.\n"
     ]
    }
   ],
   "source": [
    "# Charger la vidéo\n",
    "video = cv2.VideoCapture('my_video_TPsAV.mp4')\n",
    "if not video.isOpened():\n",
    "    print(\"Erreur : impossible de charger la vidéo.\")\n",
    "    exit()\n",
    "\n",
    "# Initialiser le tracker\n",
    "tracker = EuclideanDistTracker()\n",
    "\n",
    "# Définir les plages HSV pour détecter la couleur bleue\n",
    "lower_blue = np.array([100, 150, 50])  # Borne inférieure (teinte, saturation, luminosité)\n",
    "upper_blue = np.array([140, 255, 255])  # Borne supérieure\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        print(\"Fin de la vidéo ou erreur de lecture.\")\n",
    "        break\n",
    "\n",
    "    # Convertir l'image en espace HSV\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Créer un masque pour isoler les pixels bleus\n",
    "    mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "\n",
    "    # Nettoyage du masque avec des opérations morphologiques\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)  # Combler les trous\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)   # Supprimer le bruit\n",
    "\n",
    "    # Trouver les contours des régions bleues\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Initialiser une liste pour stocker les détections\n",
    "    detections = []\n",
    "\n",
    "    # Parcourir les contours et enregistrer les boîtes englobantes des objets pertinents\n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) > 7000:  # Filtrer les petits objets\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            detections.append([x, y, w, h])\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "    # Mettre à jour le tracker avec les nouvelles détections\n",
    "    boxes_ids = tracker.update(detections)\n",
    "\n",
    "    # Visualiser les boîtes englobantes et les IDs\n",
    "    for box_id in boxes_ids:\n",
    "        x, y, w, h, id = box_id\n",
    "        cv2.putText(frame, f\"ID {id}\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Afficher la frame avec suivi\n",
    "    cv2.imshow(\"Frame avec suivi\", frame)\n",
    "\n",
    "    # Quitter si 'q' est pressé\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7b7919",
   "metadata": {},
   "source": [
    "<b>Feature-Based tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61967e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] end of file reached\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "#Let us define the video\n",
    "# The video feed is read in as a VideoCapture object\n",
    "\n",
    "cap = cv2.VideoCapture(\"my_video_TPsAV.mp4\")\n",
    "if not cap.isOpened():\n",
    "    print(\"[ERROR] cannot open video file\")\n",
    "    sys.exit()\n",
    "\n",
    "# Generate initial corners/features from the first frame\n",
    "# Create a dict for the arguments of the main two methods: Shi Tomasi for feature extraction and Lucas and kanade OpticalFlow \n",
    "# set limit, minimum distance in pixels and quality of object corner to be tracked\n",
    "parameters_shitomasi = dict(maxCorners=100, qualityLevel=0.3, minDistance=10)\n",
    "# set min size of tracked object, e.g. 15x15px\n",
    "parameter_lucas_kanade = dict(winSize=(15, 15), maxLevel=2, criteria=(cv2.TERM_CRITERIA_EPS |\n",
    "                                                                      cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "# create random colours for visualization for all 100 max corners for RGB channels\n",
    "colours = np.random.randint(0, 255, size=(100, 3))\n",
    "\n",
    "# get first video frame\n",
    "ok, frame = cap.read()\n",
    "if not ok:\n",
    "    print(\"[ERROR] cannot get frame from video\")\n",
    "    sys.exit()\n",
    "# convert to grayscale\n",
    "frame_gray_init = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Use Shi-Tomasi to detect object corners / edges from initial frame\n",
    "edges = cv2.goodFeaturesToTrack(frame_gray_init, mask = None, **parameters_shitomasi)\n",
    "\n",
    "# [Debug] show amount of found edges\n",
    "# max value = maxCorners see above. Reduce qualityLevel to get more hits\n",
    "# print(len(edges))\n",
    "\n",
    "# create a black canvas the size of the initial frame\n",
    "canvas = np.zeros_like(frame)\n",
    "\n",
    "# Optional recording parameter\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "video_codec = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
    "prefix = 'recordings/'+datetime.datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
    "basename = \"object_track.mp4\"\n",
    "video_output = cv2.VideoWriter(\"_\".join([prefix, basename]), video_codec, fps, (frame_width, frame_height))\n",
    "\n",
    "# loop through the remaining frames of the video\n",
    "# and apply algorithm to track selected objects\n",
    "\n",
    "\n",
    "while True:\n",
    "    # get next frame\n",
    "    ok, frame = cap.read()\n",
    "    if not ok:\n",
    "        print(\"[INFO] end of file reached\")\n",
    "        break\n",
    "    # prepare grayscale image\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # update object corners by comparing with found edges in initial frame\n",
    "    update_edges, status, errors = cv2.calcOpticalFlowPyrLK(frame_gray_init, frame_gray, edges, None,\n",
    "                                                         **parameter_lucas_kanade)\n",
    "    # only update edges if algorithm successfully tracked\n",
    "    new_edges = update_edges[status == 1]\n",
    "    # to calculate directional flow we need to compare with previous position\n",
    "    old_edges = edges[status == 1]\n",
    "\n",
    "    for i, (new, old) in enumerate(zip(new_edges, old_edges)):\n",
    "        a, b = new.ravel()\n",
    "        c, d = old.ravel()\n",
    "\n",
    "        # draw line between old and new corner point with random colour\n",
    "        mask = cv2.line(canvas, (int(a), int(b)), (int(c), int(d)), colours[i].tolist(), 2)\n",
    "        # draw circle around new position\n",
    "        frame = cv2.circle(frame, (int(a), int(b)), 5, colours[i].tolist(), -1)\n",
    "\n",
    "    result = cv2.add(frame, mask)\n",
    "    # optional recording result/mask\n",
    "    # video_output.write(result)\n",
    "    cv2.imshow('Optical Flow (sparse)', result)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    # overwrite initial frame with current before restarting the loop\n",
    "    frame_gray_init = frame_gray.copy()\n",
    "    # update to new edges before restarting the loop\n",
    "    edges = new_edges.reshape(-1, 1, 2)\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb6ef67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
